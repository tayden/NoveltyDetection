{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add Bayesian-and-novelty directory to the PYTHONPATH\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.realpath('../../..'))\n",
    "\n",
    "# Autoreload changes in utils, etc.\n",
    "# %matplotlib inline\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from novelty.utils.metrics import plot_roc, plot_prc\n",
    "from novelty.utils.metrics import get_summary_statistics\n",
    "from novelty.utils.metrics import html_summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "NO_CUDA = False\n",
    "SEED = 1\n",
    "CLASSES = 5\n",
    "MODEL_PATH_ROOT = './weights/mnist5_cnn_liang2018'\n",
    "MODEL_PATH = MODEL_PATH_ROOT + '.pth'\n",
    "\n",
    "# MNIST mean and stdevs of training data by channel\n",
    "CHANNEL_MEANS = (33.430001959204674/255,)\n",
    "CHANNEL_STDS = (78.86655405163765/255,)\n",
    "\n",
    "# Plot ROC and PR curves\n",
    "PLOT_CHARTS = False\n",
    "\n",
    "# ODIN parameters\n",
    "TEMP = 1000.\n",
    "NOISE_MAGNITUDE = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelty.utils import Progbar\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    progbar = Progbar(target=len(train_loader.dataset))\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(model(data), dim=1)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progbar.add(len(data), [(\"loss\", loss.item())])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), test_acc))\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model and load MNIST0_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelty.utils import DATA_DIR\n",
    "from src.wide_resnet import Wide_ResNet\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "use_cuda = not NO_CUDA and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CHANNEL_MEANS, CHANNEL_STDS),\n",
    "])\n",
    "\n",
    "# Load training and test sets\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(DATA_DIR, 'mnist0_4/train'), transform=transform),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(DATA_DIR, 'mnist0_4/test'), transform=transform),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
    "\n",
    "# Create model instance\n",
    "model = Net().to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_PATH):\n",
    "    # load previously trained model:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "else:\n",
    "    # Training loop\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # save the model \n",
    "    torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODIN prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def predict(model, data, device):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    outputs = model(data)\n",
    "    outputs = outputs - outputs.max(1)[0].unsqueeze(1)  # For stability\n",
    "    return F.softmax(outputs, dim=1)\n",
    "\n",
    "\n",
    "def predict_temp(model, data, device, temp=1000.):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    outputs = model(data)\n",
    "    outputs /= temp\n",
    "    outputs = outputs - outputs.max(1)[0].unsqueeze(1)  # For stability\n",
    "    return F.softmax(outputs, dim=1)\n",
    "\n",
    "\n",
    "def predict_novelty(model, data, device, temp=1000., noiseMagnitude=0.0012):\n",
    "    model.eval()\n",
    "\n",
    "    # Create a variable so we can get the gradients on the input\n",
    "    inputs = Variable(data.to(device), requires_grad=True)\n",
    "\n",
    "    # Get the predicted labels\n",
    "    outputs = model(inputs)\n",
    "    outputs = outputs / temp\n",
    "    outputs = F.log_softmax(outputs, dim=1)\n",
    "\n",
    "    # Calculate the perturbation to add to the input\n",
    "    maxIndexTemp = torch.argmax(outputs, dim=1)\n",
    "    labels = Variable(maxIndexTemp).to(device)\n",
    "    loss = F.nll_loss(outputs, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    # Normalizing the gradient to binary in {0, 1}\n",
    "    gradient = torch.ge(inputs.grad.data, 0)\n",
    "    gradient = (gradient.float() - 0.5) * 2\n",
    "\n",
    "    # Normalize the gradient to the same space of image\n",
    "    for channel, (mean, std) in enumerate(zip(CHANNEL_MEANS, CHANNEL_STDS)):\n",
    "        gradient[0][channel] = (gradient[0][channel] - mean) / std\n",
    "\n",
    "    # Add small perturbations to image\n",
    "    # TODO, this is from the released code, but disagrees with paper I think\n",
    "    tempInputs = torch.add(inputs.data, -noiseMagnitude, gradient)\n",
    "\n",
    "    # Get new outputs after perturbations\n",
    "    outputs = model(Variable(tempInputs))\n",
    "    outputs = outputs / temp\n",
    "    outputs = outputs - outputs.max(1)[0].unsqueeze(1)  # For stability\n",
    "    outputs = F.softmax(outputs, dim=1)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate method on outlier datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_model_outputs(data_loader, device):\n",
    "    \"\"\"Get the max softmax output from the model in a Python array.\n",
    "\n",
    "    data_loader: object\n",
    "        A pytorch dataloader with the data you want to calculate values for.\n",
    "\n",
    "    device: object\n",
    "        The CUDA device handle.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        # Using regular model\n",
    "        p = predict(model, data, device)\n",
    "        max_val, label = torch.max(p, dim=1)\n",
    "        # Convert torch tensors to python list\n",
    "        max_val = list(max_val.cpu().detach().numpy())\n",
    "        result += max_val\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_max_odin_outputs(data_loader, device, temp=1000., noiseMagnitude=0.0012):\n",
    "    \"\"\"Convenience function to get the max softmax values from the ODIN model in a Python array.\n",
    "    \n",
    "    data_loader: object\n",
    "        A pytorch dataloader with the data you want to calculate values for.\n",
    "        \n",
    "    device: object\n",
    "        The CUDA device handle.\n",
    "        \n",
    "    temp: float, optional (default=1000.)\n",
    "        The temp the model should use to do temperature scaling on the softmax outputs.\n",
    "        \n",
    "    noiseMagnitude: float, optional (default=0.0012)\n",
    "        The epsilon value used to scale the input images according to the ODIN paper.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        # Using ODIN model\n",
    "        p = predict_novelty(model, data, device, temp=temp, noiseMagnitude=noiseMagnitude)\n",
    "        max_val, label = torch.max(p, dim=1)\n",
    "        # Convert torch tensors to python list\n",
    "        max_val = list(max_val.cpu().detach().numpy())\n",
    "        result += max_val\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['auroc', 'aupr_in', 'aupr_out', 'fpr_at_95_tpr', 'detection_error'],\n",
    "                  index=['letters', 'rot90', 'gaussian', 'uniform', 'not_mnist', 'mnist5_9'])\n",
    "\n",
    "df_odin = pd.DataFrame(columns=['auroc', 'aupr_in', 'aupr_out', 'fpr_at_95_tpr', 'detection_error'],\n",
    "                  index=['letters', 'rot90', 'gaussian', 'uniform', 'not_mnist', 'mnist5_9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inliers = len(test_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "mnist_model_maximums = get_max_model_outputs(test_loader, device)\n",
    "mnist_odin_maximums = get_max_odin_outputs(test_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(DATA_DIR, 'fashion_mnist')\n",
    "\n",
    "# Dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CHANNEL_MEANS, CHANNEL_STDS),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "fashion_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(directory, train=False, transform=transform, download=True),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "num_fashion = len(fashion_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "fashion_model_maximums = get_max_model_outputs(fashion_loader, device)\n",
    "fashion_odin_maximums = get_max_odin_outputs(fashion_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_fashion\n",
    "predictions = mnist_model_maximums + fashion_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + fashion_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['fashion'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['fashion'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMNIST Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(DATA_DIR, 'emnist')\n",
    "\n",
    "# Dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CHANNEL_MEANS, CHANNEL_STDS),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "emnist_loader = torch.utils.data.DataLoader(\n",
    "        datasets.EMNIST(directory, \"letters\", train=False, transform=transform, download=True),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "num_emnist = len(emnist_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "emnist_model_maximums = get_max_model_outputs(emnist_loader, device)\n",
    "emnist_odin_maximums = get_max_odin_outputs(emnist_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_emnist\n",
    "predictions = mnist_model_maximums + emnist_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + emnist_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['letters'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['letters'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(DATA_DIR, 'notmnist/notMNIST_small')\n",
    "\n",
    "# Dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CHANNEL_MEANS, CHANNEL_STDS),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "notmnist_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(directory, transform=transform),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "num_notmnist = len(notmnist_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "notmnist_model_maximums = get_max_model_outputs(notmnist_loader, device)\n",
    "notmnist_odin_maximums = get_max_odin_outputs(notmnist_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_notmnist\n",
    "predictions = mnist_model_maximums + notmnist_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + notmnist_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['not_mnist'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['not_mnist'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotated 90 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(DATA_DIR, 'mnist')\n",
    "\n",
    "# Dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda image: image.rotate(90)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CHANNEL_MEANS, CHANNEL_STDS),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "rot90_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(directory, train=False, transform=transform, download=True),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "num_rot90 = len(rot90_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "rot90_model_maximums = get_max_model_outputs(rot90_loader, device)\n",
    "rot90_odin_maximums = get_max_odin_outputs(rot90_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_rot90\n",
    "predictions = mnist_model_maximums + rot90_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + rot90_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['rot90'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['rot90'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelty.utils.datasets import GaussianNoiseDataset\n",
    "\n",
    "gaussian_transform = transforms.Compose([\n",
    "    #TODO clip to [0,1] range\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "gaussian_loader = torch.utils.data.DataLoader(\n",
    "    GaussianNoiseDataset((10000, 28, 28, 1), mean=0., std=1., transform=gaussian_transform),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "num_gaussian = len(gaussian_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "gaussian_model_maximums = get_max_model_outputs(gaussian_loader, device)\n",
    "gaussian_odin_maximums = get_max_odin_outputs(\n",
    "    gaussian_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_gaussian\n",
    "predictions = mnist_model_maximums + gaussian_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + gaussian_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['gaussian'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['gaussian'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelty.utils.datasets import UniformNoiseDataset\n",
    "import math\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "uniform_loader = torch.utils.data.DataLoader(\n",
    "    UniformNoiseDataset((10000, 28, 28, 1), low=-math.sqrt(3.), high=math.sqrt(3.), transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "num_uniform = len(uniform_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "uniform_model_maximums = get_max_model_outputs(uniform_loader, device)\n",
    "uniform_odin_maximums = get_max_odin_outputs(\n",
    "    uniform_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_uniform\n",
    "predictions = mnist_model_maximums + uniform_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + uniform_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['uniform'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['uniform'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST5_9 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CHANNEL_MEANS, CHANNEL_STDS),\n",
    "])\n",
    "\n",
    "# Load training and test sets\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "mnist5_9_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(DATA_DIR, 'mnist5_9/test'), transform=transform),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
    "\n",
    "num_mnist5_9 = len(mnist5_9_loader.dataset)\n",
    "\n",
    "# Get predictions on in-distribution images\n",
    "mnist5_9_model_maximums = get_max_model_outputs(mnist5_9_loader, device)\n",
    "mnist5_9_odin_maximums = get_max_odin_outputs(\n",
    "    mnist5_9_loader, device, temp=TEMP, noiseMagnitude=NOISE_MAGNITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = [1] * num_inliers + [0] * num_mnist5_9\n",
    "predictions = mnist_model_maximums + mnist5_9_model_maximums\n",
    "predictions_odin = mnist_odin_maximums + mnist5_9_odin_maximums\n",
    "\n",
    "stats = get_summary_statistics(predictions, labels)\n",
    "df.loc['5-9'] = pd.Series(stats)\n",
    "\n",
    "stats_odin = get_summary_statistics(predictions_odin, labels)\n",
    "df_odin.loc['5-9'] = pd.Series(stats_odin)\n",
    "\n",
    "if PLOT_CHARTS:\n",
    "    plot_roc(predictions, labels, title=\"Softmax Thresholding ROC Curve\")\n",
    "    plot_roc(predictions_odin, labels, title=\"ODIN ROC Curve\")\n",
    "\n",
    "#     plot_prc(predictions, labels, title=\"Softmax Thresholding PRC Curve\")\n",
    "#     plot_prc(predictions_odin, labels, title=\"ODIN PRC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./results/mnist5_cnn_liang2018.pkl')\n",
    "df_odin.to_pickle('./results/mnist5_cnn_odin_liang2018.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auroc</th>\n",
       "      <th>aupr_in</th>\n",
       "      <th>aupr_out</th>\n",
       "      <th>fpr_at_95_tpr</th>\n",
       "      <th>detection_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>letters</th>\n",
       "      <td>0.869460</td>\n",
       "      <td>0.740112</td>\n",
       "      <td>0.963088</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>0.496782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rot90</th>\n",
       "      <td>0.868785</td>\n",
       "      <td>0.829815</td>\n",
       "      <td>0.928473</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.497342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaussian</th>\n",
       "      <td>0.633103</td>\n",
       "      <td>0.687178</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.497742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.628235</td>\n",
       "      <td>0.685441</td>\n",
       "      <td>0.822466</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.498192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_mnist</th>\n",
       "      <td>0.865330</td>\n",
       "      <td>0.748952</td>\n",
       "      <td>0.959304</td>\n",
       "      <td>0.992256</td>\n",
       "      <td>0.496420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnist5_9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>0.967253</td>\n",
       "      <td>0.968941</td>\n",
       "      <td>0.957914</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>0.497692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-9</th>\n",
       "      <td>0.869532</td>\n",
       "      <td>0.899924</td>\n",
       "      <td>0.863997</td>\n",
       "      <td>0.995680</td>\n",
       "      <td>0.498132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              auroc   aupr_in  aupr_out  fpr_at_95_tpr  detection_error\n",
       "letters    0.869460  0.740112  0.963088       0.992981         0.496782\n",
       "rot90      0.868785  0.829815  0.928473       0.994100         0.497342\n",
       "gaussian   0.633103  0.687178  0.826816       0.994900         0.497742\n",
       "uniform    0.628235  0.685441  0.822466       0.995800         0.498192\n",
       "not_mnist  0.865330  0.748952  0.959304       0.992256         0.496420\n",
       "mnist5_9        NaN       NaN       NaN            NaN              NaN\n",
       "fashion    0.967253  0.968941  0.957914       0.994800         0.497692\n",
       "5-9        0.869532  0.899924  0.863997       0.995680         0.498132"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auroc</th>\n",
       "      <th>aupr_in</th>\n",
       "      <th>aupr_out</th>\n",
       "      <th>fpr_at_95_tpr</th>\n",
       "      <th>detection_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>letters</th>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>0.982431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rot90</th>\n",
       "      <td>0.923509</td>\n",
       "      <td>0.850484</td>\n",
       "      <td>0.961089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaussian</th>\n",
       "      <td>0.865286</td>\n",
       "      <td>0.838545</td>\n",
       "      <td>0.898373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.865795</td>\n",
       "      <td>0.842376</td>\n",
       "      <td>0.896594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_mnist</th>\n",
       "      <td>0.934871</td>\n",
       "      <td>0.832400</td>\n",
       "      <td>0.980033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnist5_9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>0.972829</td>\n",
       "      <td>0.979663</td>\n",
       "      <td>0.985958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-9</th>\n",
       "      <td>0.937609</td>\n",
       "      <td>0.950066</td>\n",
       "      <td>0.933961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              auroc   aupr_in  aupr_out  fpr_at_95_tpr  detection_error\n",
       "letters    0.936544  0.842991  0.982431            1.0              0.5\n",
       "rot90      0.923509  0.850484  0.961089            1.0              0.5\n",
       "gaussian   0.865286  0.838545  0.898373            1.0              0.5\n",
       "uniform    0.865795  0.842376  0.896594            1.0              0.5\n",
       "not_mnist  0.934871  0.832400  0.980033            1.0              0.5\n",
       "mnist5_9        NaN       NaN       NaN            NaN              NaN\n",
       "fashion    0.972829  0.979663  0.985958            1.0              0.5\n",
       "5-9        0.937609  0.950066  0.933961            1.0              0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_odin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
